{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from transformers import BertTokenizer, TFBertModel, TFDistilBertModel\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "import os\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Processing_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubsSeYSNr_Um",
        "outputId": "b1982355-6b20-4d8d-f4bb-4f2c2c188ebf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   label                                            message\n",
            "0      0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...\n",
            "1      0  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...\n",
            "2      1  Bobby Jindal, raised Hindu, uses story of Chri...\n",
            "3      0  SATAN 2: Russia unvelis an image of its terrif...\n",
            "4      0  About Time! Christian Group Sues Amazon and SP...\n"
          ]
        }
      ],
      "source": [
        "# URL du dataset\n",
        "url = 'https://fnd-jedha-project.s3.eu-west-3.amazonaws.com/0_WELFake_workbase.csv'\n",
        "\n",
        "# Chargement du dataset\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Affichage des premières lignes du dataset\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5gfo-5br__D",
        "outputId": "719599a9-f9dd-4f25-9931-910da8b4b4cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   label                                            message\n",
            "0      0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...\n",
            "1      0  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...\n",
            "2      1  Bobby Jindal, raised Hindu, uses story of Chri...\n",
            "3      0  SATAN 2: Russia unvelis an image of its terrif...\n",
            "4      0  About Time! Christian Group Sues Amazon and SP...\n"
          ]
        }
      ],
      "source": [
        "# Fonction de suppression des URLs\n",
        "def remove_urls(text):\n",
        "    # Supprimer les URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    return text\n",
        "\n",
        "# Appliquer la fonction de suppression des URLs aux textes\n",
        "df['message'] = df['message'].apply(remove_urls)\n",
        "\n",
        "# Affichage des premières lignes du dataset nettoyé\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdIljgKrtkBL",
        "outputId": "711bd2ca-6650-4a3a-8b40-90383e568d6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set size: 50496\n",
            "Validation set size: 12625\n"
          ]
        }
      ],
      "source": [
        "# Séparation des données\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    df['message'], df['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "print(f'Training set size: {len(train_texts)}')\n",
        "print(f'Validation set size: {len(val_texts)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Zi0ClGeABcK",
        "outputId": "43b841c3-d89d-4363-fb65-6fa5a3a65335"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2673: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train input_ids shape: (50496, 1, 128)\n",
            "Train attention_masks shape: (50496, 1, 128)\n",
            "Val input_ids shape: (12625, 1, 128)\n",
            "Val attention_masks shape: (12625, 1, 128)\n"
          ]
        }
      ],
      "source": [
        "# Chargement du tokenizer BERT\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Fonction de tokenisation\n",
        "def encode_data(texts, tokenizer, max_len):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in texts:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='tf',\n",
        "        )\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    return tf.convert_to_tensor(input_ids), tf.convert_to_tensor(attention_masks)\n",
        "\n",
        "# Tokenisation des textes\n",
        "max_len = 128\n",
        "train_input_ids, train_attention_masks = encode_data(train_texts, tokenizer, max_len)\n",
        "val_input_ids, val_attention_masks = encode_data(val_texts, tokenizer, max_len)\n",
        "\n",
        "# Affichage des dimensions des tenseurs\n",
        "print(f'Train input_ids shape: {train_input_ids.shape}')\n",
        "print(f'Train attention_masks shape: {train_attention_masks.shape}')\n",
        "print(f'Val input_ids shape: {val_input_ids.shape}')\n",
        "print(f'Val attention_masks shape: {val_attention_masks.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ww109s1Vt2go",
        "outputId": "ed4520b7-f9fa-4c65-dc59-d3ffc01e84b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train input_ids shape: (50496, 128)\n",
            "Train attention_masks shape: (50496, 128)\n",
            "Val input_ids shape: (12625, 128)\n",
            "Val attention_masks shape: (12625, 128)\n"
          ]
        }
      ],
      "source": [
        "# Chargement du tokenizer BERT\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Fonction de tokenisation\n",
        "def encode_data(texts, tokenizer, max_len):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in texts:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='tf',\n",
        "            truncation=True  # Ajout de l'argument truncation\n",
        "        )\n",
        "        input_ids.append(encoded_dict['input_ids'][0])  # Suppression de la dimension supplémentaire\n",
        "        attention_masks.append(encoded_dict['attention_mask'][0])  # Suppression de la dimension supplémentaire\n",
        "\n",
        "    return tf.convert_to_tensor(input_ids), tf.convert_to_tensor(attention_masks)\n",
        "\n",
        "# Tokenisation des textes\n",
        "max_len = 128\n",
        "train_input_ids, train_attention_masks = encode_data(train_texts, tokenizer, max_len)\n",
        "val_input_ids, val_attention_masks = encode_data(val_texts, tokenizer, max_len)\n",
        "\n",
        "# Affichage des dimensions des tenseurs\n",
        "print(f'Train input_ids shape: {train_input_ids.shape}')\n",
        "print(f'Train attention_masks shape: {train_attention_masks.shape}')\n",
        "print(f'Val input_ids shape: {val_input_ids.shape}')\n",
        "print(f'Val attention_masks shape: {val_attention_masks.shape}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPbnGGvE0MGX"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "FHkWEgPew-LE",
        "outputId": "9323b3a7-7e87-4ece-fb02-43f36ad92c68"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"news_classifier\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"news_classifier\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "class NewsClassifier(tf.keras.Model):\n",
        "    def __init__(self, n_classes):\n",
        "        super(NewsClassifier, self).__init__()\n",
        "        self.bert = TFBertModel.from_pretrained('bert-base-uncased')\n",
        "        self.dropout = Dropout(0.3)\n",
        "        self.classifier = Dense(n_classes, activation='softmax')\n",
        "\n",
        "    def call(self, inputs, attention_mask=None, token_type_ids=None, training=False):\n",
        "        outputs = self.bert(inputs, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        pooled_output = outputs[1]\n",
        "        pooled_output = self.dropout(pooled_output, training=training)\n",
        "        return self.classifier(pooled_output)\n",
        "\n",
        "# Création du modèle\n",
        "model = NewsClassifier(n_classes=2)\n",
        "\n",
        "# Affichage de la structure du modèle\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bI2RiVis0I6I",
        "outputId": "35907737-fffa-4147-da89-06abb8299160"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"tf_bert_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bert (TFBertMainLayer)      multiple                  109482240 \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109482240 (417.64 MB)\n",
            "Trainable params: 109482240 (417.64 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Affichage de la structure complète du modèle BERT\n",
        "model.bert.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtdryLSXKgRP",
        "outputId": "0de88d4e-a7cf-4a6b-aa73-dcf5868d9c7d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m3156/3156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 79ms/step - accuracy: 0.6610 - loss: 0.6416 - val_accuracy: 0.8265 - val_loss: 0.4063\n",
            "Epoch 2/10\n",
            "\u001b[1m3156/3156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 76ms/step - accuracy: 0.8183 - loss: 0.4063 - val_accuracy: 0.8516 - val_loss: 0.3538\n",
            "Epoch 3/10\n",
            "\u001b[1m3156/3156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 76ms/step - accuracy: 0.8467 - loss: 0.3601 - val_accuracy: 0.8661 - val_loss: 0.3277\n",
            "Epoch 4/10\n",
            "\u001b[1m3156/3156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 87ms/step - accuracy: 0.8594 - loss: 0.3374 - val_accuracy: 0.8734 - val_loss: 0.3105\n",
            "Epoch 5/10\n",
            "\u001b[1m3156/3156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 76ms/step - accuracy: 0.8626 - loss: 0.3234 - val_accuracy: 0.8790 - val_loss: 0.2993\n",
            "Epoch 6/10\n",
            "\u001b[1m3156/3156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 76ms/step - accuracy: 0.8697 - loss: 0.3130 - val_accuracy: 0.8805 - val_loss: 0.2900\n",
            "Epoch 7/10\n",
            "\u001b[1m3156/3156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 76ms/step - accuracy: 0.8745 - loss: 0.3050 - val_accuracy: 0.8851 - val_loss: 0.2836\n",
            "Epoch 8/10\n",
            "\u001b[1m3156/3156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 76ms/step - accuracy: 0.8754 - loss: 0.3011 - val_accuracy: 0.8865 - val_loss: 0.2778\n",
            "Epoch 9/10\n",
            "\u001b[1m3156/3156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 87ms/step - accuracy: 0.8760 - loss: 0.2959 - val_accuracy: 0.8908 - val_loss: 0.2737\n",
            "Epoch 10/10\n",
            "\u001b[1m3156/3156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 76ms/step - accuracy: 0.8788 - loss: 0.2912 - val_accuracy: 0.8911 - val_loss: 0.2693\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fc961b758d0>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class NewsClassifier(tf.keras.Model):\n",
        "    def __init__(self, n_classes):\n",
        "        super(NewsClassifier, self).__init__()\n",
        "        self.bert = TFDistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "        self.dropout = Dropout(0.3)\n",
        "        self.classifier = Dense(n_classes)  # Suppression de l'activation softmax\n",
        "\n",
        "    def call(self, inputs, attention_mask=None, training=False):\n",
        "        outputs = self.bert(inputs, attention_mask=attention_mask)\n",
        "        pooled_output = outputs[0][:, 0, :]  # Utiliser la sortie du premier token [CLS]\n",
        "        pooled_output = self.dropout(pooled_output, training=training)\n",
        "        return self.classifier(pooled_output)\n",
        "\n",
        "# Création du modèle\n",
        "model = NewsClassifier(n_classes=2)\n",
        "\n",
        "# Compilation du modèle avec un taux d'apprentissage plus élevé\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Création des datasets TensorFlow\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(({'input_ids': train_input_ids, 'attention_mask': train_attention_masks}, train_labels))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices(({'input_ids': val_input_ids, 'attention_mask': val_attention_masks}, val_labels))\n",
        "\n",
        "# Batching et shuffling des datasets avec une taille de batch plus petite\n",
        "train_dataset = train_dataset.shuffle(1000).batch(16)\n",
        "val_dataset = val_dataset.batch(16)\n",
        "\n",
        "# Entraînement du modèle avec plus d'époques\n",
        "model.fit(train_dataset, epochs=10, validation_data=val_dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFKqxVbIWEut",
        "outputId": "00fa4de0-ef01-4989-be39-c41a34e568fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 62ms/step - accuracy: 0.8877 - loss: 0.2746\n",
            "Validation Loss: 0.2692555785179138\n",
            "Validation Accuracy: 0.8910890817642212\n"
          ]
        }
      ],
      "source": [
        "# Évaluation du modèle\n",
        "val_loss, val_accuracy = model.evaluate(val_dataset)\n",
        "print(f'Validation Loss: {val_loss}')\n",
        "print(f'Validation Accuracy: {val_accuracy}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jpXeGJcXf07"
      },
      "source": [
        "# Saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "chIxCncPWeak"
      },
      "outputs": [],
      "source": [
        "# Création du répertoire s'il n'existe pas\n",
        "os.makedirs('fake_news_detector', exist_ok=True)\n",
        "\n",
        "# Sauvegarde du modèle en format .keras\n",
        "model.save('fake_news_detector/model.keras')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "P5WLX3kUW_6Y"
      },
      "outputs": [],
      "source": [
        "# Sauvegarde des poids du modèle\n",
        "model.save_weights('fake_news_detector/model_weights.weights.h5')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9dACb9XXvdx"
      },
      "source": [
        "## Téléchargement des Fichiers Sauvegardés sur pc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "h7lnTzDmXVLU",
        "outputId": "05a730e5-124f-44ce-a534-88950c0a713b"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_e321aa05-db56-4dc4-9000-a8b4660f2b6d\", \"model.keras\", 29909)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_14fb560b-25ec-48a8-9c18-99266f1b6305\", \"model_weights.weights.h5\", 31584)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Téléchargement du fichier du modèle\n",
        "files.download('fake_news_detector/model.keras')\n",
        "\n",
        "# Téléchargement du fichier des poids du modèle\n",
        "files.download('fake_news_detector/model_weights.weights.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvSMLh8GZipG",
        "outputId": "11a12bfe-3142-4245-a0db-b5c495bbff0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['model.pkl', 'model.keras', 'model_weights.weights.h5']\n"
          ]
        }
      ],
      "source": [
        "# Lister les fichiers dans le répertoire fake_news_detector\n",
        "files = os.listdir('fake_news_detector')\n",
        "print(files)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUSFPQtNXZhU",
        "outputId": "8a66d8ad-32e5-4f02-98ea-fe106d78647b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['.config', 'fake_news_detector', 'sample_data']\n"
          ]
        }
      ],
      "source": [
        "# Lister les fichiers dans le répertoire courant\n",
        "files = os.listdir('.')\n",
        "print(files)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
