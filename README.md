Fake News Detection 
SynthÃ¨se des ExpÃ©riences avec DiffÃ©rents ModÃ¨les

ğŸŒŸ Projet de DÃ©tection de Fake News
ğŸ’ª Ã‰quipe : Mohamed Boumrar, Fred Mendes, Yannick Howaton

ğŸŒ Contexte
Dans le cadre de ce projet, nous avons explorÃ© plusieurs approches pour dÃ©tecter les fake news Ã  partir de donnÃ©es textuelles. Nous avons testÃ© diffÃ©rentes techniques et architectures afin de comparer leur efficacitÃ© et optimiser les performances de classification.

ğŸ¯ Objectif
L'objectif global Ã©tait de dÃ©velopper plusieurs modÃ¨les capables de dÃ©tecter les fake news et d'analyser leurs performances respectives. Nous avons explorÃ© trois approches principales :
TF-IDF + RÃ©gression Logistique avec et sans Ponctuation : AmÃ©lioration de la vectorisation TF-IDF en conservant la ponctuation pour de meilleures performances.
3. TF-IDF + RÃ©gression Logistique avec SMOTE : Approche basÃ©e sur la vectorisation TF-IDF et une rÃ©gression logistique pour la classification.
2. BERT : Utilisation de BERT (Bidirectional Encoder Representations from Transformers) pour une meilleure comprÃ©hension du contexte global.

________________________________________

ğŸ“ ModÃ©lisation et ExpÃ©riences

ğŸ’¡ 1. TF-IDF + RÃ©gression Logistique avec et sans Ponctuation
Pourquoi cette approche ?
- L'inclusion de la ponctuation permettrait de capturer davantage de nuances dans le texte.
- TF-IDF permet d'extraire efficacement les caractÃ©ristiques textuelles.
- RÃ©gression logistique pour une classification rapide et performante.

ProblÃ¨mes et solutions :
- SensibilitÃ© Ã  la qualitÃ© des textes â†’ PrÃ©traitement avancÃ© et nettoyage optimisÃ©.

ğŸ“Š RÃ©sultats :
- Accuracy : 91%
- F1-score : 90% / 92%
- Bon compromis entre rapiditÃ© et prÃ©cision.
â€”â€”â€”â€”â€”â€”â€”â€”
ğŸŒŸ 2. TF-IDF + RÃ©gression Logistique avec SMOTE
Pourquoi cette approche ?
- TF-IDF pour extraire les caractÃ©ristiques textuelles.
- RÃ©gression logistique comme modÃ¨le simple et efficace.
- SMOTE pour corriger le dÃ©sÃ©quilibre des classes.

ProblÃ¨mes et solutions :
- DÃ©sÃ©quilibre des classes â†’ Utilisation de SMOTE.

ğŸ“Š RÃ©sultats :
- Accuracy : 95.81%
- F1-score : 95.75%
- Approche Ã©quilibrÃ©e entre performance et complexitÃ©.
________________________________________

ğŸ” 3. BERT pour la dÃ©tection de fake news
Pourquoi BERT ?
BERT est un modÃ¨le de transformer bidirectionnel prÃ©-entraidnÃ©, extrÃªmement puissant pour le NLP.

DifficultÃ©s et solutions :
- Ressources lourdes â†’ Utilisation de DistilBERT pour rÃ©duire la complexitÃ©.

ğŸ“Š RÃ©sultats :
- Accuracy : 90% sur les donnÃ©es de test.
- Meilleures performances mais fortement coÃ»teux.


________________________________________

ğŸ“ˆ Conclusion GÃ©nÃ©rale

| ModÃ¨le | Accuracy | Points forts | Limitations |
|---------|---------|--------------|--------------|
| BERT | 90% | PrÃ©cision trÃ¨s Ã©levÃ©e | Exigeant en ressources |
| TF-IDF + RÃ©gression Logistique (Ponctuation) | 91% | Bon compromis entre rapiditÃ© et prÃ©cision | Sensible Ã  la qualitÃ© des donnÃ©es |
| TF-IDF + Logistic Regression (SMOTE) | 95.81% | Bonne performance et gestion des classes | Moins adaptÃ© aux contextes complexes |

SynthÃ¨se :
- BERT est le plus prÃ©cis mais trÃ¨s coÃ»teux.
- TF-IDF + RÃ©gression Logistique (Ponctuation) est rapide et efficace.
- TF-IDF + Logistic Regression (SMOTE) est performant et bien Ã©quilibrÃ©.

ğŸ› ï¸ Installation et Utilisation:
Chargez le modÃ¨le et prÃ©dire un article :
```python
import pickle
with open('logistic_regression_model_smote.pkl', 'rb') as model_file:
    model = pickle.load(model_file)
prediction = model.predict([article_text])
```
________________________________________
